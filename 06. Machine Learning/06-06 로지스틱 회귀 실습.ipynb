{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **06-06 로지스틱 회귀 실습**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtGVlhhrUw20"
      },
      "source": [
        "이 자료는 위키독스 딥 러닝을 이용한 자연어 처리 입문의 로지스틱 회귀의 튜토리얼 자료입니다.  \n",
        "\n",
        "링크 : https://wikidocs.net/111476"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "로지스틱 회귀를 케라스를 통해 구현해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1. 케라스로 구현하는 로지스틱 회귀**\n",
        "독립 변수 데이터를 x, 숫자 10 이상인 경우에는 1, 미만인 경우에는 0을 부여한 레이블 데이터를 y라고 해봅시다.\n",
        "\n",
        "이번 데이터는 앞서 배운 단순 선형 회귀때와 마찬가지로 1개의 실수 x로부터 1개의 실수인 y를 예측하는 맵핑 관계를 가지므로 Dense의 output_dim, input_dim 인자값으로 각각 1을 기재합니다. 시그모이드 함수를 사용할 것이므로 activation의 인자값으로는 sigmoid를 기재해줍니다.\n",
        "\n",
        "옵티마이저로는 가장 기본적인 경사 하강법인 sgd를 사용하였습니다. 시그모이드 함수를 사용한 이진 분류 문제에 손실 함수로 크로스 엔트로피 함수를 사용할 경우 binary_crossentropy를 기재해주면 됩니다. 에포크는 200으로 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OOG_-p5GexzZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFO3rbEge1Z5",
        "outputId": "6ad3f8f6-0556-4eec-d14c-95cef2db52c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\dlwlg\\anaconda3\\envs\\py310_yolo\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - binary_accuracy: 0.1538 - loss: 1.9849\n",
            "Epoch 2/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - binary_accuracy: 0.9231 - loss: 0.2162\n",
            "Epoch 3/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.2139\n",
            "Epoch 4/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - binary_accuracy: 0.9231 - loss: 0.2121\n",
            "Epoch 5/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9231 - loss: 0.2105\n",
            "Epoch 6/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9231 - loss: 0.2091\n",
            "Epoch 7/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - binary_accuracy: 0.9231 - loss: 0.2080\n",
            "Epoch 8/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.2070\n",
            "Epoch 9/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.2061\n",
            "Epoch 10/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - binary_accuracy: 0.9231 - loss: 0.2053\n",
            "Epoch 11/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9231 - loss: 0.2045\n",
            "Epoch 12/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.2039\n",
            "Epoch 13/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - binary_accuracy: 0.9231 - loss: 0.2033\n",
            "Epoch 14/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - binary_accuracy: 0.9231 - loss: 0.2028\n",
            "Epoch 15/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.9231 - loss: 0.2023\n",
            "Epoch 16/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - binary_accuracy: 0.9231 - loss: 0.2018\n",
            "Epoch 17/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - binary_accuracy: 0.9231 - loss: 0.2014\n",
            "Epoch 18/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.2010\n",
            "Epoch 19/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.2007\n",
            "Epoch 20/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9231 - loss: 0.2003\n",
            "Epoch 21/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.9231 - loss: 0.2000\n",
            "Epoch 22/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1997\n",
            "Epoch 23/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1994\n",
            "Epoch 24/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.1991\n",
            "Epoch 25/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1989\n",
            "Epoch 26/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.9231 - loss: 0.1986\n",
            "Epoch 27/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - binary_accuracy: 0.9231 - loss: 0.1984\n",
            "Epoch 28/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1982\n",
            "Epoch 29/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1979\n",
            "Epoch 30/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1977\n",
            "Epoch 31/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - binary_accuracy: 0.9231 - loss: 0.1975\n",
            "Epoch 32/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1973\n",
            "Epoch 33/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1971\n",
            "Epoch 34/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1969\n",
            "Epoch 35/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1967\n",
            "Epoch 36/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1966\n",
            "Epoch 37/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - binary_accuracy: 0.9231 - loss: 0.1964\n",
            "Epoch 38/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1962\n",
            "Epoch 39/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1960\n",
            "Epoch 40/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - binary_accuracy: 0.9231 - loss: 0.1959\n",
            "Epoch 41/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.9231 - loss: 0.1957\n",
            "Epoch 42/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - binary_accuracy: 0.9231 - loss: 0.1956\n",
            "Epoch 43/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - binary_accuracy: 0.9231 - loss: 0.1954\n",
            "Epoch 44/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1952\n",
            "Epoch 45/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1951\n",
            "Epoch 46/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - binary_accuracy: 0.9231 - loss: 0.1949\n",
            "Epoch 47/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1948\n",
            "Epoch 48/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1947\n",
            "Epoch 49/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - binary_accuracy: 0.9231 - loss: 0.1945\n",
            "Epoch 50/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.1944\n",
            "Epoch 51/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1942\n",
            "Epoch 52/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1941\n",
            "Epoch 53/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1939\n",
            "Epoch 54/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.9231 - loss: 0.1938\n",
            "Epoch 55/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - binary_accuracy: 0.9231 - loss: 0.1937\n",
            "Epoch 56/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.9231 - loss: 0.1935\n",
            "Epoch 57/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1934\n",
            "Epoch 58/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1933\n",
            "Epoch 59/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1931\n",
            "Epoch 60/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.9231 - loss: 0.1930\n",
            "Epoch 61/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1929\n",
            "Epoch 62/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - binary_accuracy: 0.9231 - loss: 0.1927\n",
            "Epoch 63/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1926\n",
            "Epoch 64/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - binary_accuracy: 0.9231 - loss: 0.1925\n",
            "Epoch 65/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1923\n",
            "Epoch 66/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1922\n",
            "Epoch 67/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.9231 - loss: 0.1921\n",
            "Epoch 68/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.9231 - loss: 0.1920\n",
            "Epoch 69/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - binary_accuracy: 0.9231 - loss: 0.1918\n",
            "Epoch 70/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.1917\n",
            "Epoch 71/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - binary_accuracy: 0.9231 - loss: 0.1916\n",
            "Epoch 72/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1914\n",
            "Epoch 73/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1913\n",
            "Epoch 74/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1912\n",
            "Epoch 75/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1911\n",
            "Epoch 76/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.1909\n",
            "Epoch 77/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.9231 - loss: 0.1908\n",
            "Epoch 78/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - binary_accuracy: 0.9231 - loss: 0.1907\n",
            "Epoch 79/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.1906\n",
            "Epoch 80/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - binary_accuracy: 0.9231 - loss: 0.1905\n",
            "Epoch 81/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9231 - loss: 0.1903\n",
            "Epoch 82/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - binary_accuracy: 0.9231 - loss: 0.1902\n",
            "Epoch 83/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1901\n",
            "Epoch 84/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - binary_accuracy: 0.9231 - loss: 0.1900\n",
            "Epoch 85/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - binary_accuracy: 0.9231 - loss: 0.1898\n",
            "Epoch 86/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9231 - loss: 0.1897\n",
            "Epoch 87/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1896\n",
            "Epoch 88/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1895\n",
            "Epoch 89/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1894\n",
            "Epoch 90/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1892\n",
            "Epoch 91/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - binary_accuracy: 0.9231 - loss: 0.1891\n",
            "Epoch 92/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1890\n",
            "Epoch 93/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9231 - loss: 0.1889\n",
            "Epoch 94/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - binary_accuracy: 0.9231 - loss: 0.1888\n",
            "Epoch 95/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.9231 - loss: 0.1886\n",
            "Epoch 96/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - binary_accuracy: 0.9231 - loss: 0.1885\n",
            "Epoch 97/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1884\n",
            "Epoch 98/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - binary_accuracy: 0.9231 - loss: 0.1883\n",
            "Epoch 99/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - binary_accuracy: 0.9231 - loss: 0.1882\n",
            "Epoch 100/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1881\n",
            "Epoch 101/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1879\n",
            "Epoch 102/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1878\n",
            "Epoch 103/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1877\n",
            "Epoch 104/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.9231 - loss: 0.1876\n",
            "Epoch 105/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.9231 - loss: 0.1875\n",
            "Epoch 106/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.1873\n",
            "Epoch 107/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.1872\n",
            "Epoch 108/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - binary_accuracy: 0.9231 - loss: 0.1871\n",
            "Epoch 109/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1870\n",
            "Epoch 110/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1869\n",
            "Epoch 111/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1868\n",
            "Epoch 112/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - binary_accuracy: 0.9231 - loss: 0.1866\n",
            "Epoch 113/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - binary_accuracy: 0.9231 - loss: 0.1865\n",
            "Epoch 114/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - binary_accuracy: 0.9231 - loss: 0.1864\n",
            "Epoch 115/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1863\n",
            "Epoch 116/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1862\n",
            "Epoch 117/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1861\n",
            "Epoch 118/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - binary_accuracy: 0.9231 - loss: 0.1860\n",
            "Epoch 119/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - binary_accuracy: 0.9231 - loss: 0.1858\n",
            "Epoch 120/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.9231 - loss: 0.1857\n",
            "Epoch 121/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1856\n",
            "Epoch 122/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9231 - loss: 0.1855\n",
            "Epoch 123/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1854\n",
            "Epoch 124/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1853\n",
            "Epoch 125/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1852\n",
            "Epoch 126/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - binary_accuracy: 0.9231 - loss: 0.1850\n",
            "Epoch 127/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.9231 - loss: 0.1849\n",
            "Epoch 128/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1848\n",
            "Epoch 129/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - binary_accuracy: 0.9231 - loss: 0.1847\n",
            "Epoch 130/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - binary_accuracy: 0.9231 - loss: 0.1846\n",
            "Epoch 131/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1845\n",
            "Epoch 132/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - binary_accuracy: 0.9231 - loss: 0.1844\n",
            "Epoch 133/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1842\n",
            "Epoch 134/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9231 - loss: 0.1841\n",
            "Epoch 135/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1840\n",
            "Epoch 136/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1839\n",
            "Epoch 137/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9231 - loss: 0.1838\n",
            "Epoch 138/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1837\n",
            "Epoch 139/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1836\n",
            "Epoch 140/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1835\n",
            "Epoch 141/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1833\n",
            "Epoch 142/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - binary_accuracy: 0.9231 - loss: 0.1832\n",
            "Epoch 143/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1831\n",
            "Epoch 144/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - binary_accuracy: 0.9231 - loss: 0.1830\n",
            "Epoch 145/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - binary_accuracy: 0.9231 - loss: 0.1829\n",
            "Epoch 146/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1828\n",
            "Epoch 147/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - binary_accuracy: 0.9231 - loss: 0.1827\n",
            "Epoch 148/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1826\n",
            "Epoch 149/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - binary_accuracy: 0.9231 - loss: 0.1825\n",
            "Epoch 150/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1824\n",
            "Epoch 151/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - binary_accuracy: 0.9231 - loss: 0.1822\n",
            "Epoch 152/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1821\n",
            "Epoch 153/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1820\n",
            "Epoch 154/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1819\n",
            "Epoch 155/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1818\n",
            "Epoch 156/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1817\n",
            "Epoch 157/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1816\n",
            "Epoch 158/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1815\n",
            "Epoch 159/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - binary_accuracy: 0.9231 - loss: 0.1814\n",
            "Epoch 160/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - binary_accuracy: 0.9231 - loss: 0.1813\n",
            "Epoch 161/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - binary_accuracy: 0.9231 - loss: 0.1811\n",
            "Epoch 162/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1810\n",
            "Epoch 163/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1809\n",
            "Epoch 164/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1808\n",
            "Epoch 165/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1807\n",
            "Epoch 166/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1806\n",
            "Epoch 167/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1805\n",
            "Epoch 168/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1804\n",
            "Epoch 169/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1803\n",
            "Epoch 170/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1802\n",
            "Epoch 171/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1801\n",
            "Epoch 172/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1800\n",
            "Epoch 173/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1799\n",
            "Epoch 174/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1797\n",
            "Epoch 175/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - binary_accuracy: 0.9231 - loss: 0.1796\n",
            "Epoch 176/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1795\n",
            "Epoch 177/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1794\n",
            "Epoch 178/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1793\n",
            "Epoch 179/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1792\n",
            "Epoch 180/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1791\n",
            "Epoch 181/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1790\n",
            "Epoch 182/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1789\n",
            "Epoch 183/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1788\n",
            "Epoch 184/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1787\n",
            "Epoch 185/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1786\n",
            "Epoch 186/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1785\n",
            "Epoch 187/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1784\n",
            "Epoch 188/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1783\n",
            "Epoch 189/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - binary_accuracy: 0.9231 - loss: 0.1782\n",
            "Epoch 190/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - binary_accuracy: 0.9231 - loss: 0.1780\n",
            "Epoch 191/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1779\n",
            "Epoch 192/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1778\n",
            "Epoch 193/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1777\n",
            "Epoch 194/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - binary_accuracy: 0.9231 - loss: 0.1776\n",
            "Epoch 195/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1775\n",
            "Epoch 196/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1774\n",
            "Epoch 197/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1773\n",
            "Epoch 198/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1772\n",
            "Epoch 199/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - binary_accuracy: 0.9231 - loss: 0.1771\n",
            "Epoch 200/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1770\n",
            "Epoch 201/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1769\n",
            "Epoch 202/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1768\n",
            "Epoch 203/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1767\n",
            "Epoch 204/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1766\n",
            "Epoch 205/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - binary_accuracy: 0.9231 - loss: 0.1765\n",
            "Epoch 206/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - binary_accuracy: 0.9231 - loss: 0.1764\n",
            "Epoch 207/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1763\n",
            "Epoch 208/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1762\n",
            "Epoch 209/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - binary_accuracy: 0.9231 - loss: 0.1761\n",
            "Epoch 210/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1760\n",
            "Epoch 211/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1759\n",
            "Epoch 212/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1758\n",
            "Epoch 213/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1757\n",
            "Epoch 214/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.9231 - loss: 0.1756\n",
            "Epoch 215/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1755\n",
            "Epoch 216/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9231 - loss: 0.1754\n",
            "Epoch 217/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1753\n",
            "Epoch 218/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1752\n",
            "Epoch 219/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1751\n",
            "Epoch 220/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1750\n",
            "Epoch 221/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1749\n",
            "Epoch 222/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.9231 - loss: 0.1748\n",
            "Epoch 223/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1747\n",
            "Epoch 224/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1746\n",
            "Epoch 225/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1745\n",
            "Epoch 226/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1744\n",
            "Epoch 227/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.9231 - loss: 0.1743\n",
            "Epoch 228/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - binary_accuracy: 0.9231 - loss: 0.1742\n",
            "Epoch 229/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1741\n",
            "Epoch 230/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1740\n",
            "Epoch 231/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - binary_accuracy: 0.9231 - loss: 0.1739\n",
            "Epoch 232/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1738\n",
            "Epoch 233/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9231 - loss: 0.1737\n",
            "Epoch 234/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1736\n",
            "Epoch 235/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1735\n",
            "Epoch 236/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1734\n",
            "Epoch 237/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - binary_accuracy: 0.9231 - loss: 0.1733\n",
            "Epoch 238/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1732\n",
            "Epoch 239/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1731\n",
            "Epoch 240/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1730\n",
            "Epoch 241/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1729\n",
            "Epoch 242/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1728\n",
            "Epoch 243/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - binary_accuracy: 0.9231 - loss: 0.1727\n",
            "Epoch 244/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - binary_accuracy: 0.9231 - loss: 0.1726\n",
            "Epoch 245/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1725\n",
            "Epoch 246/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1724\n",
            "Epoch 247/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1723\n",
            "Epoch 248/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1722\n",
            "Epoch 249/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1721\n",
            "Epoch 250/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1720\n",
            "Epoch 251/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1719\n",
            "Epoch 252/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1718\n",
            "Epoch 253/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1717\n",
            "Epoch 254/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1716\n",
            "Epoch 255/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1715\n",
            "Epoch 256/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - binary_accuracy: 0.9231 - loss: 0.1714\n",
            "Epoch 257/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1713\n",
            "Epoch 258/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1712\n",
            "Epoch 259/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1711\n",
            "Epoch 260/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1710\n",
            "Epoch 261/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - binary_accuracy: 0.9231 - loss: 0.1709\n",
            "Epoch 262/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - binary_accuracy: 0.9231 - loss: 0.1708\n",
            "Epoch 263/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1707\n",
            "Epoch 264/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - binary_accuracy: 0.9231 - loss: 0.1706\n",
            "Epoch 265/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1705\n",
            "Epoch 266/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1704\n",
            "Epoch 267/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1703\n",
            "Epoch 268/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1703\n",
            "Epoch 269/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1702\n",
            "Epoch 270/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1701\n",
            "Epoch 271/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1700\n",
            "Epoch 272/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1699\n",
            "Epoch 273/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1698\n",
            "Epoch 274/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1697\n",
            "Epoch 275/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - binary_accuracy: 0.9231 - loss: 0.1696\n",
            "Epoch 276/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - binary_accuracy: 0.9231 - loss: 0.1695\n",
            "Epoch 277/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - binary_accuracy: 0.9231 - loss: 0.1694\n",
            "Epoch 278/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1693\n",
            "Epoch 279/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1692\n",
            "Epoch 280/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1691\n",
            "Epoch 281/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1690\n",
            "Epoch 282/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1689\n",
            "Epoch 283/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - binary_accuracy: 0.9231 - loss: 0.1688\n",
            "Epoch 284/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1687\n",
            "Epoch 285/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1686\n",
            "Epoch 286/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - binary_accuracy: 0.9231 - loss: 0.1686\n",
            "Epoch 287/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - binary_accuracy: 0.9231 - loss: 0.1685\n",
            "Epoch 288/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1684\n",
            "Epoch 289/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - binary_accuracy: 0.9231 - loss: 0.1683\n",
            "Epoch 290/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - binary_accuracy: 0.9231 - loss: 0.1682\n",
            "Epoch 291/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1681\n",
            "Epoch 292/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1680\n",
            "Epoch 293/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1679\n",
            "Epoch 294/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - binary_accuracy: 0.9231 - loss: 0.1678\n",
            "Epoch 295/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1677\n",
            "Epoch 296/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1676\n",
            "Epoch 297/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - binary_accuracy: 0.9231 - loss: 0.1675\n",
            "Epoch 298/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - binary_accuracy: 0.9231 - loss: 0.1674\n",
            "Epoch 299/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1674\n",
            "Epoch 300/300\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - binary_accuracy: 0.9231 - loss: 0.1673\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x257061f4910>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])\n",
        "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]) # 숫자 10부터 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
        "\n",
        "# sgd = optimizers.SGD(lr=0.01)\n",
        "sgd = optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "\n",
        "model.fit(x, y, epochs=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "총 200회에 걸쳐 전체 데이터에 대한 오차를 최소화하는 w\n",
        "와 b\n",
        "를 찾아내는 작업을 합니다. 저자의 경우 약 190회부터 정확도가 100%가 나오기 시작했습니다. 실제값과 오차를 최소화하도록 값이 변경된 w\n",
        "와 b\n",
        "의 값을 가진 모델을 이용하여 그래프를 그려보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "_qAvKFnze45n",
        "outputId": "7a6578eb-83c5-4789-8184-133046d1c3c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x257063602b0>,\n",
              " <matplotlib.lines.Line2D at 0x25706361120>]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(x, model.predict(x), 'b', x,y, 'k.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "x의 값이 5와 10사이의 어떤 값일때 y값이 0.5가 넘기 시작하는 것처럼 보입니다. 정확도가 100%가 나왔었기 때문에 적어도 x의 값이 5일때는 y값이 0.5보다 작고, x의 값이 10일 때는 y값이 0.5를 넘을 것입니다. 이제 x의 값이 5보다 작은 값일 때와 x의 값이 10보다 클 때에 대해서 y값을 출력해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GzgwZEte5vH",
        "outputId": "988cd61e-204c-474f-d555-0b99e7789640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "[[0.4774029 ]\n",
            " [0.53354347]\n",
            " [0.5888471 ]\n",
            " [0.6419935 ]\n",
            " [0.667398  ]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "[[0.8963961]\n",
            " [0.987944 ]\n",
            " [0.9987132]\n",
            " [0.999864 ]\n",
            " [1.       ]]\n"
          ]
        }
      ],
      "source": [
        "## 리스트로 입력시 에러 발생 -> numpy array로 입력할것!\n",
        "# print(model.predict([1, 2, 3, 4, 4.5]))\n",
        "# print(model.predict([11, 21, 31, 41, 500]))\n",
        "\n",
        "print(model.predict(np.array([1, 2, 3, 4, 4.5])))\n",
        "print(model.predict(np.array([11, 21, 31, 41, 500]))) #, verbose=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "x의 값이 5보다 작을 때는 0.5보다 작은 값을, x의 값이 10보다 클 때는 0.5보다 큰 값을 출력하는 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "로지스틱 회귀.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py310_yolo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
