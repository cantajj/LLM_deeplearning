{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13362,
     "status": "ok",
     "timestamp": 1724225746161,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "YpJR21lC2Vbc",
    "outputId": "c63a846d-8cdb-45ce-adf3-2ae567eed1d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n",
      "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3998,
     "status": "ok",
     "timestamp": 1724225750155,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "uqpe2ou-2Vbe",
    "outputId": "86bb5f1c-4724-4a3d-fdad-bcdaa4765743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태깅이 된 문장 개수:  3914\n"
     ]
    }
   ],
   "source": [
    "# 토큰화에 품사 태깅이 된 데이터 받아오기\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
    "print(\"품사 태깅이 된 문장 개수: \", len(tagged_sentences))\n",
    "\n",
    "# 문장과 태그를 분리\n",
    "sentences, sentence_tags = [], []\n",
    "\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(list(sentence))\n",
    "    sentence_tags.append(list(tags))\n",
    "\n",
    "# 단어와 태그에 대한 인덱스화\n",
    "words = [word.lower() for sentence in sentences for word in sentence]\n",
    "tags = [tag for tag_seq in sentence_tags for tag in tag_seq]\n",
    "\n",
    "word2idx = {w: i + 2 for i, w in enumerate(list(set(words)))}\n",
    "word2idx['PAD'] = 0  # 패딩용 인덱스\n",
    "word2idx['OOV'] = 1  # 사전에 없는 단어(Out-Of-Vocabulary) 용 인덱스\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(list(set(tags)))}\n",
    "tag2idx['PAD'] = 0  # 패딩용 인덱스\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "idx2tag = {i: t for t, i in tag2idx.items()}\n",
    "\n",
    "# 문장을 정수 인덱스로 변환\n",
    "X = [[word2idx.get(w.lower(), word2idx['OOV']) for w in s] for s in sentences]\n",
    "y = [[tag2idx[t] for t in ts] for ts in sentence_tags]\n",
    "\n",
    "# 패딩 추가\n",
    "max_len = 100\n",
    "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
    "y = pad_sequences(y, maxlen=max_len, padding='post')\n",
    "\n",
    "# 출력 값은 one-hot 인코딩\n",
    "y = [to_categorical(i, num_classes=len(tag2idx)) for i in y]\n",
    "\n",
    "# 학습 및 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1724225750735,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "i69m16rx2Vbf",
    "outputId": "f5cb5725-835e-4cbe-84ac-352928fac94b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "hidden_units = 64\n",
    "vocab_size = len(word2idx)\n",
    "tag_size = len(tag2idx)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=hidden_units, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0005), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 780083,
     "status": "ok",
     "timestamp": 1724226530814,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "5fenXXBk2Vbf",
    "outputId": "749f0188-6f31-4b8d-ad41-c82174aaef4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 355ms/step - accuracy: 0.1310 - loss: 2.1506 - val_accuracy: 0.2030 - val_loss: 0.8247\n",
      "Epoch 2/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 353ms/step - accuracy: 0.2116 - loss: 0.6032 - val_accuracy: 0.2416 - val_loss: 0.2588\n",
      "Epoch 3/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 349ms/step - accuracy: 0.2481 - loss: 0.1698 - val_accuracy: 0.2476 - val_loss: 0.1755\n",
      "Epoch 4/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 342ms/step - accuracy: 0.2496 - loss: 0.0857 - val_accuracy: 0.2485 - val_loss: 0.1559\n",
      "Epoch 5/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 351ms/step - accuracy: 0.2510 - loss: 0.0595 - val_accuracy: 0.2485 - val_loss: 0.1595\n",
      "Epoch 6/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 441ms/step - accuracy: 0.2487 - loss: 0.0484 - val_accuracy: 0.2495 - val_loss: 0.1472\n",
      "Epoch 7/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 368ms/step - accuracy: 0.2514 - loss: 0.0361 - val_accuracy: 0.2496 - val_loss: 0.1452\n",
      "Epoch 8/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 374ms/step - accuracy: 0.2526 - loss: 0.0279 - val_accuracy: 0.2496 - val_loss: 0.1480\n",
      "Epoch 9/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 387ms/step - accuracy: 0.2501 - loss: 0.0229 - val_accuracy: 0.2493 - val_loss: 0.1564\n",
      "Epoch 10/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 371ms/step - accuracy: 0.2516 - loss: 0.0196 - val_accuracy: 0.2495 - val_loss: 0.1532\n",
      "Epoch 11/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 371ms/step - accuracy: 0.2543 - loss: 0.0142 - val_accuracy: 0.2494 - val_loss: 0.1617\n",
      "Epoch 12/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 370ms/step - accuracy: 0.2532 - loss: 0.0121 - val_accuracy: 0.2495 - val_loss: 0.1650\n",
      "Epoch 13/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 366ms/step - accuracy: 0.2569 - loss: 0.0096 - val_accuracy: 0.2489 - val_loss: 0.1686\n",
      "Epoch 14/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 380ms/step - accuracy: 0.2567 - loss: 0.0080 - val_accuracy: 0.2490 - val_loss: 0.1776\n",
      "Epoch 15/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 397ms/step - accuracy: 0.2526 - loss: 0.0066 - val_accuracy: 0.2486 - val_loss: 0.1787\n",
      "Epoch 16/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 390ms/step - accuracy: 0.2546 - loss: 0.0045 - val_accuracy: 0.2487 - val_loss: 0.1822\n",
      "Epoch 17/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 397ms/step - accuracy: 0.2589 - loss: 0.0039 - val_accuracy: 0.2489 - val_loss: 0.1895\n",
      "Epoch 18/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 398ms/step - accuracy: 0.2550 - loss: 0.0034 - val_accuracy: 0.2488 - val_loss: 0.1869\n",
      "Epoch 19/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 400ms/step - accuracy: 0.2548 - loss: 0.0025 - val_accuracy: 0.2484 - val_loss: 0.1937\n",
      "Epoch 20/20\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 389ms/step - accuracy: 0.2561 - loss: 0.0025 - val_accuracy: 0.2482 - val_loss: 0.1969\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# # Eager Execution 활성화\n",
    "# tf.config.run_functions_eagerly(True)  # 디버깅 시에만 활성활\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, np.array(y_train), batch_size=32, epochs=20, validation_split=0.1, verbose=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1724226531389,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "-qVF58cA2Vbf",
    "outputId": "d45d8e28-dd37-4e8c-f48a-37d9f71acf77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "[('This', 'DET'), ('is', 'VERB'), ('a', 'DET'), ('simple', 'ADJ'), ('test', 'NOUN'), ('sentence.', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "def predict_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    x_test = pad_sequences([[word2idx.get(w.lower(), word2idx['OOV']) for w in words]], maxlen=max_len, padding='post')\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    tags = [idx2tag[i] for i in y_pred[0] if i != 0]  # PAD 값은 제외\n",
    "    return list(zip(words, tags))\n",
    "\n",
    "test_sentence = \"This is a simple test sentence.\"\n",
    "print(predict_sentence(test_sentence))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
