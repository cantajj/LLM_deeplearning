{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afbdeba",
   "metadata": {
    "id": "5afbdeba"
   },
   "source": [
    "## **15-03 양방향 LSTM과 어텐션 메커니즘(BiLSTM with Attention mechanism)**\n",
    "\n",
    "단뱡항 LSTM으로 텍스트 분류를 수행할 수도 있지만 때로는 **양방향 LSTM** 을 사용하는 것이 더 강력합니다. 여기에 추가적으로 **어텐션 메커니즘** 을 사용할 수도 있습니다. 양방향 LSTM과 어텐션 메커니즘으로 IMDB 리뷰 감성 분류하기를 수행해봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eUfU0rP7dDQk",
   "metadata": {
    "id": "eUfU0rP7dDQk"
   },
   "source": [
    "\n",
    "### **1.IMDB 리뷰 데이터 전처리하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df409969",
   "metadata": {
    "executionInfo": {
     "elapsed": 13452,
     "status": "ok",
     "timestamp": 1747155934366,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "df409969"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a436b15",
   "metadata": {
    "id": "2a436b15"
   },
   "source": [
    "IMDB 리뷰 데이터는 앞서 텍스트 분류하기 챕터에서 다룬 바 있으므로 데이터에 대한 상세 설명은 생략합니다. 최대 단어 개수를 10,000으로 제한하고 훈련 데이터와 테스트 데이터를 받아옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc5a5fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6766,
     "status": "ok",
     "timestamp": 1747155941136,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "5cc5a5fe",
    "outputId": "e1d93f3f-6789-4b47-c872-17f66cdd0e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "_R3UOyzlgIfD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1747155941160,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "_R3UOyzlgIfD",
    "outputId": "bf7cb896-edb3-4d8f-deac-0495650138e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vYldNeCDgMpr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747155941168,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "vYldNeCDgMpr",
    "outputId": "ec6d98eb-6a48-425b-c51c-2b87361c7478"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), array([1, 0, 0, ..., 0, 1, 0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77526821",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747157191929,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "77526821"
   },
   "outputs": [],
   "source": [
    "# imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca35e01",
   "metadata": {
    "id": "7ca35e01"
   },
   "source": [
    "훈련 데이터와 이에 대한 레이블이 각각 X_train, y_train에 테스트 데이터와 이에 대한 레이블이 각각 X_test, y_test에 저장되었습니다. IMDB 리뷰 데이터는 이미 정수 인코딩이 된 상태므로 남은 전처리는 패딩뿐입니다. 리뷰의 최대 길이와 평균 길이를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40fac075",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1747155941421,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "40fac075",
    "outputId": "af09f47c-d1cb-4375-9fea-807a8a783580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 2494\n",
      "리뷰의 평균 길이 : 238.71364\n"
     ]
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
    "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b4188c",
   "metadata": {
    "id": "12b4188c"
   },
   "source": [
    "리뷰의 최대 길이는 2,494이며 리뷰의 평균 길이는 약 238로 확인됩니다. 평균 길이보다는 조금 크게 데이터를 패딩하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d168cf",
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1747155941866,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "d3d168cf"
   },
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "# Colab GPU 사용시 Error: 반드시 우측 Padding 되어야 함 (CuDNN)\n",
    "###########################################################################\n",
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "JFx4Y8KKfq0-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1747155941877,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "JFx4Y8KKfq0-",
    "outputId": "478292c6-6fef-4393-801a-41fe624c3843"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 500),\n",
       " array([[   1,   14,   22, ...,    0,    0,    0],\n",
       "        [   1,  194, 1153, ...,    0,    0,    0],\n",
       "        [   1,   14,   47, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,   11,    6, ...,    0,    0,    0],\n",
       "        [   1, 1446, 7079, ...,    0,    0,    0],\n",
       "        [   1,   17,    6, ...,    0,    0,    0]], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "KMnErNYlfsmm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747155941897,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "KMnErNYlfsmm",
    "outputId": "bb41c30d-a5b8-4ddc-c592-8a950a1d9712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 500),\n",
       " array([[   1,  591,  202, ...,    0,    0,    0],\n",
       "        [   1,   14,   22, ...,    0,    0,    0],\n",
       "        [  33,    6,   58, ...,    9,   57,  975],\n",
       "        ...,\n",
       "        [   1,   13, 1408, ...,    0,    0,    0],\n",
       "        [   1,   11,  119, ...,    0,    0,    0],\n",
       "        [   1,    6,   52, ...,    0,    0,    0]], dtype=int32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696f45b",
   "metadata": {
    "id": "1696f45b"
   },
   "source": [
    "훈련용 리뷰와 테스트용 리뷰의 길이가 둘 다 500이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d4084",
   "metadata": {
    "id": "ce9d4084"
   },
   "source": [
    "### **2.바다나우 어텐션(Bahdanau Attention)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6_M9VMdldaU8",
   "metadata": {
    "id": "6_M9VMdldaU8"
   },
   "source": [
    "여기서 사용할 어텐션은 바다나우 어텐션(Bahdanau attention)입니다. 이를 이해하기 위해 앞서 배운 가장 쉬운 어텐션이었던 닷 프로덕트 어텐션과 어텐션 스코어 함수의 정의를 상기해봅시다.\n",
    "\n",
    "어텐션 스코어 함수란 주어진 query와 모든 key에 대해서 유사도를 측정하는 함수를 말합니다. 그리고 닷 프로덕트 어텐션에서는 query와 key의 유사도를 구하는 방법이 내적(dot product)이었습니다. 다음은 닷 프로덕트 어텐션의 어텐션 스코어 함수를 보여줍니다.\n",
    "\n",
    "##### $score(query, key) = query^T key$\n",
    "  \n",
    "\n",
    "바다나우 어텐션은 아래와 같은 어텐션 스코어 함수를 사용합니다.\n",
    "  \n",
    "##### $score(query, key) = V^T tanh(W_1 key + W_2 query)$\n",
    "  \n",
    "  \n",
    "이 어텐션 스코어 함수를 사용하여 어텐션 메커니즘을 구현하면 됩니다. 그런데 텍스트 분류에서 어텐션 메커니즘을 사용하는 이유는 무엇일까요? RNN의 마지막 은닉 상태는 예측을 위해 사용됩니다. 그런데 이 RNN의 마지막 은닉 상태는 몇 가지 유용한 정보들을 손실한 상태입니다. 그래서 RNN이 time step을 지나며 손실했던 정보들을 다시 참고하고자 합니다.\n",
    "\n",
    "이는 다시 말해 RNN의 모든 은닉 상태들을 다시 한 번 참고하겠다는 것입니다. 그리고 이를 위해서 어텐션메커니즘을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4465aff",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747155941899,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "e4465aff"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f9321e",
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1747155941958,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "36f9321e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import register_keras_serializable  # Import for serialization\n",
    "\n",
    "@register_keras_serializable()  #  BahdanauAttention이라는 사용자 정의 클래스가 직렬화(Serialization) 및 역직렬화(Deserialization) 과정에서 인식되지 않아서 발생한 오류 해결용\n",
    "class BahdanauAttention(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = Dense(units)\n",
    "    self.W2 = Dense(units)\n",
    "    self.V = Dense(1)\n",
    "\n",
    "  def call(self, values, query): # 단, key와 value는 같음\n",
    "    # query shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f21a6",
   "metadata": {
    "id": "056f21a6"
   },
   "source": [
    "### **3.양방향 LSTM + 어텐션 메커니즘(BiLSTM with Attention Mechanism)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b009f4b",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1747155942009,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "7b009f4b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca513b8",
   "metadata": {
    "id": "bca513b8"
   },
   "source": [
    "이제 모델을 설계해보겠습니다. 여기서는 케라스의 함수형 API를 사용합니다. 우선 입력층과 임베딩층을 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898e511f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2709,
     "status": "ok",
     "timestamp": 1747155944716,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "898e511f",
    "outputId": "8df4f754-49fe-4c57-e801-c516127726d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb42e18",
   "metadata": {
    "id": "fdb42e18"
   },
   "source": [
    "10,000개의 단어들을 128차원의 벡터로 임베딩하도록 설계하였습니다. 이제 양방향 LSTM을 설계합니다. 단, 여기서는 양방향 LSTM을 두 층을 사용하겠습니다. 우선, 첫번째 층입니다. 두번째 층을 위에 쌓을 예정이므로 return_sequences를 True로 해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2281f016",
   "metadata": {
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1747155944867,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "2281f016"
   },
   "outputs": [],
   "source": [
    "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55194248",
   "metadata": {
    "id": "55194248"
   },
   "source": [
    "두번째 층을 설계합니다. 상태를 리턴받아야 하므로 return_state를 True로 해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "375c5ecd",
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1747155944908,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "375c5ecd"
   },
   "outputs": [],
   "source": [
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
    "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25947b7",
   "metadata": {
    "id": "b25947b7"
   },
   "source": [
    "각 상태의 크기(shape)를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfd9495f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1747155944948,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "bfd9495f",
    "outputId": "f2c887b8-7169-4126-fa06-a0224d66f069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
     ]
    }
   ],
   "source": [
    "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b83326",
   "metadata": {
    "id": "30b83326"
   },
   "source": [
    "순방향 LSTM의 은닉 상태와 셀상태를 forward_h, forward_c에 저장하고, 역방향 LSTM의 은닉 상태와 셀 상태를 backward_h, backward_c에 저장합니다.\n",
    "\n",
    "각 은닉 상태나 셀 상태의 경우에는 128차원을 가지는데, lstm의 경우에는 (500 × 128)의 크기를 가집니다. foward 방향과 backward 방향이 연결된 hidden state벡터가 모든 시점에 대해서 존재함을 의미합니다.\n",
    "\n",
    "양방향 LSTM을 사용할 경우에는 순방향 LSTM과 역방향 LSTM 각각 은닉 상태와 셀 상태를 가지므로, 양방향 LSTM의 은닉 상태와 셀 상태를 사용하려면 두 방향의 LSTM의 상태들을 연결(concatenate)해주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27bc33fe",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1747155944967,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "27bc33fe"
   },
   "outputs": [],
   "source": [
    "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
    "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rEcmFJdXZfak",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747155944977,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "rEcmFJdXZfak",
    "outputId": "8cad0826-dfdf-4316-fbe9-dd0074971e41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor shape=(None, 128), dtype=float32, sparse=False, name=keras_tensor_9>,\n",
       " <KerasTensor shape=(None, 128), dtype=float32, sparse=False, name=keras_tensor_10>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_h, state_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf407a9",
   "metadata": {
    "id": "ecf407a9"
   },
   "source": [
    "어텐션 메커니즘에서는 은닉 상태를 사용합니다. 이를 입력으로 컨텍스트 벡터(context vector)를 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4784b391",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1747155945101,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "4784b391",
    "outputId": "369f9347-0a87-43e2-ec55-c1629e7ad0d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'bahdanau_attention' (of type BahdanauAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
    "context_vector, attention_weights = attention(lstm, state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4Dx8PNyoZsjg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1747155945107,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "4Dx8PNyoZsjg",
    "outputId": "62278655-1552-4ae8-d8cd-6085f98cb293"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BahdanauAttention name=bahdanau_attention, built=True>,\n",
       " <KerasTensor shape=(None, 128), dtype=float32, sparse=False, name=keras_tensor_13>,\n",
       " <KerasTensor shape=(None, 500, 1), dtype=float32, sparse=False, name=keras_tensor_14>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention, context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92702412",
   "metadata": {
    "id": "92702412"
   },
   "source": [
    "컨텍스트 벡터를 밀집층(dense layer)에 통과시키고, 이진 분류이므로 최종 출력층에 1개의 뉴런을 배치하고, 활성화 함수로 시그모이드 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0e96051",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1747155945113,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "b0e96051"
   },
   "outputs": [],
   "source": [
    "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
    "model = Model(inputs=sequence_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "JXo0FiugZ7_x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747155945115,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "JXo0FiugZ7_x",
    "outputId": "a054080c-fbd5-4d6b-ed67-95235d239d17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor shape=(None, 20), dtype=float32, sparse=False, name=keras_tensor_15>,\n",
       " <KerasTensor shape=(None, 20), dtype=float32, sparse=False, name=keras_tensor_16>,\n",
       " <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_17>,\n",
       " <Functional name=functional, built=True>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1, dropout, output, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1607daa",
   "metadata": {
    "id": "b1607daa"
   },
   "source": [
    "옵티마이저로 아담 옵티마이저 사용하고, 모델을 컴파일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9070348d",
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1747155945163,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "9070348d"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "276ed5ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1747155945186,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "276ed5ff",
    "outputId": "fad1a060-844a-42c5-c9c4-9c7188499ca0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>,      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>), │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bahdanau_attention  │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,577</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BahdanauAttention</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)]   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580</span> │ bahdanau_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m1,280,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m98,816\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m,      │     \u001b[38;5;34m98,816\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m), │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bahdanau_attention  │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │     \u001b[38;5;34m16,577\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBahdanauAttention\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)]   │            │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │      \u001b[38;5;34m2,580\u001b[0m │ bahdanau_attenti… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m21\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,496,810</span> (5.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,496,810\u001b[0m (5.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,496,810</span> (5.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,496,810\u001b[0m (5.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e9ec9",
   "metadata": {
    "id": "9d0e9ec9"
   },
   "source": [
    "시그모이드 함수를 사용하므로 손실 함수로 binary_crossentropy를 사용하였습니다. 이제 모델을 훈련하겠습니다.  \n",
    "검증 데이터로 테스트 데이터를 사용하여 에포크가 끝날 때마다 테스트 데이터에 대한 정확도를 출력하도록 하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76a493d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85340,
     "status": "ok",
     "timestamp": 1747156030522,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "76a493d3",
    "outputId": "d2815ad2-0ab2-427a-d707-ea6bd964b30f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 189ms/step - accuracy: 0.6464 - loss: 0.6055 - val_accuracy: 0.8728 - val_loss: 0.3067\n",
      "Epoch 2/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 180ms/step - accuracy: 0.9062 - loss: 0.2651 - val_accuracy: 0.8768 - val_loss: 0.2984\n",
      "Epoch 3/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 180ms/step - accuracy: 0.9333 - loss: 0.1947 - val_accuracy: 0.8801 - val_loss: 0.3029\n",
      "CPU times: user 48.5 s, sys: 6.22 s, total: 54.7 s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# colab - Epoch 3/3\n",
    "# 98/98 [==============================] - 1170s 12s/step - loss: 0.1934 - accuracy: 0.9379 - val_loss: 0.3021 - val_accuracy: 0.8785\n",
    "# CPU times: user 1h 42min 41s, sys: 8min 55s, total: 1h 51min 37s\n",
    "# Wall time: 59min 37s\n",
    "\n",
    "# colab GPU : 2024.08 (Padding 이 반드시 padding='post'로 우측 padding이 되어야 함)\n",
    "# Epoch 3/3\n",
    "# 98/98 ━━━━━━━━━━━━━━━━━━━━ 35s 191ms/step - accuracy: 0.9239 - loss: 0.2146 - val_accuracy: 0.8803 - val_loss: 0.3061\n",
    "# CPU times: user 54.3 s, sys: 5.76 s, total: 1min\n",
    "# Wall time: 1min 30s\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=256, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "675ed282",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21054,
     "status": "ok",
     "timestamp": 1747156051577,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "675ed282",
    "outputId": "2e5497dc-a783-478b-b678-0969cdd69feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.8783 - loss: 0.3037\n",
      "\n",
      " 테스트 정확도: 0.8787\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "JRwOlqtXakGb",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1747157333444,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "JRwOlqtXakGb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fR1cN67WrWPp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1747157388666,
     "user": {
      "displayName": "전정호",
      "userId": "01748710418857244015"
     },
     "user_tz": -540
    },
    "id": "fR1cN67WrWPp",
    "outputId": "fc1f4c44-797a-4a97-e175-a7777ed0527e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩된 리뷰:\n",
      "\n",
      "<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss\n"
     ]
    }
   ],
   "source": [
    "## 정수 인코딩 시퀀스를 문장으로 확인해 보기\n",
    "# 1. 데이터 로드\n",
    "# vocab_size = 10000\n",
    "# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# 2. 단어 인덱스 로드\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# 3. index → word 매핑 딕셔너리 생성\n",
    "# Keras는 사전에 1~3번까지의 인덱스를 reserved token으로 사용하므로 +3 offset 필요\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<START>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "# 4. 디코딩 함수 정의\n",
    "def decode_review(encoded_review):\n",
    "    return ' '.join([index_to_word.get(i, '?') for i in encoded_review])\n",
    "\n",
    "# 5. 첫 번째 훈련 샘플 디코딩\n",
    "decoded = decode_review(X_test[0])\n",
    "print(\"디코딩된 리뷰:\\n\")\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "On6IcPM1sVUh",
   "metadata": {
    "id": "On6IcPM1sVUh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310_yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
